# Natours - Agile Lab Project Documentation

## Sprint 0: Planning

### Personal Context & Starting Point

**Date Started:** December 03, 2026
**Expected Completion:** February 18, 2026

**My Background with This Project:**

- I've worked with the Natours project before in a tutorial, so I'm familiar with the codebase structure
- My weakest area is testing - I understand the concept but struggle with writing good tests
- I've used Git before but never properly set up GitHub Actions
- I want to use this project to finally understand CI/CD properly

**What I Want to Learn:**

1. How to write tests that actually catch bugs (not just dummy tests)
2. How to set up automated pipelines without following a tutorial step-by-step
3. How to structure a project so it's actually maintainable
4. What "monitoring" really means for a small project

---

### 1. Product Vision

**Natours** is a tour booking platform that enables adventure travelers to discover, explore, and book exciting nature tours. For this lab, I'm focusing on the **backend API** with:

- Tour management (CRUD operations)
- User authentication
- Booking functionality
- Stripe payment
- Map integration
- Real DevOps practices applied throughout

_Note: I'm intentionally keeping scope small so I can focus on Agile/DevOps practices rather than building features._

---

### 2. Initial Product Backlog

#### Priority Legend

**High** - Must have for core functionality
**Medium** - Important but can wait
**Low** - Nice to have

---

#### User Story #1: Automated Testing Suite

**Priority: High | Story Points: 5**

**As a** developer
**I want** automated tests to run on every code push
**So that** I can catch bugs early and ensure code quality

**Acceptance Criteria:**

- Unit tests are written for at least 3 critical functions
- Tests run automatically in CI/CD pipeline
- Test coverage report is generated
- Pipeline fails if tests fail

**My Implementation Notes:**

- Need to learn Jest syntax properly
- Plan to test: tour model validation, API response format, error handling
- Concern: How to test database interactions without affecting real data?
- Research needed: MongoDB memory server vs mocking

**Questions I Have:**

- Should I aim for 100% coverage or just critical paths?
- How do I test file uploads?

---

#### User Story #2: CI/CD Pipeline Setup

**Priority: High | Story Points: 8**

**As a** developer
**I want** an automated CI/CD pipeline
**So that** code is automatically tested and deployment-ready

**Acceptance Criteria:**

- GitHub Actions workflow file is configured
- Pipeline runs on push to main branch
- Linting checks are included
- Build process completes successfully
- Pipeline status is visible in repository

**My Implementation Plan:**

```
Week 1 Goals:
- Day 1-2: Research GitHub Actions syntax
- Day 3: Create basic workflow file
- Day 4: Test with simple "hello world" commit
- Day 5: Add linting and build steps
- Weekend: Debug any issues
```

**Resources Bookmarked:**

- GitHub Actions documentation
- "CI/CD for Node.js" tutorial I found

**Potential Problems I Foresee:**

- YAML syntax errors (always happens)
- Environment variables not working in CI
- Tests passing locally but failing in CI

---

#### User Story #3: Health Monitoring Endpoint

**Priority: Medium | Story Points: 3**

**As a** DevOps engineer
**I want** a health check endpoint
**So that** I can monitor if the application is running correctly

**Acceptance Criteria:**

- GET /api/v1/health returns server status
- Response includes timestamp and status code 200
- Endpoint is accessible without authentication
- Response includes basic system info

**Why This Matters to Me:**

- First time implementing monitoring
- Will help me understand what "observability" means
- Simple win to build confidence

**Implementation Sketch:**

```javascript
// Pseudo-code I'll work from
health endpoint {
  status: 'ok',
  message: 'Server is running'
  timestamp: new Date(),
  uptime: process.uptime(),
  environment: process.env.NODE_ENV,
  nodeVersion: process.version
}
```

---

#### User Story #4: Error Logging & Monitoring

**Priority: Medium | Story Points: 5**

**As a** developer
**I want** comprehensive error logging
**So that** I can track and debug issues in production

**Acceptance Criteria:**

- All errors logged with timestamp and stack trace
- Logs include request context
- Different log levels implemented
- Logs written to files in production

**Research Needed:**

- Compare Winston vs Morgan vs Pino
- Log rotation? (maybe overkill for this project)
- Should I log to console or files?

**Decision to Make Later:**
Start with simple console.log for Sprint 1, implement proper logging in Sprint 2 based on what I learn.

---

#### User Story #5: Tour API Documentation

**Priority: Low | Story Points: 3**

**As a** API consumer
**I want** clear API documentation
**So that** I can understand how to interact with the endpoints

**Acceptance Criteria:**

- README.md includes API documentation
- Each endpoint has description, method, sample response
- Authentication requirements stated
- Example curl commands provided

**Personal Note:**
I always skip documentation in my projects, but I know it's important. Making this a formal user story so I don't forget.

---

#### User Story #6: Input Validation Tests

**Priority: Medium | Story Points: 5**

**As a** developer
**I want** comprehensive input validation tests
**So that** the API rejects invalid data correctly

**Acceptance Criteria:**

- Tests verify required fields validation
- Tests verify data type validation
- Tests verify malformed requests return appropriate errors
- Tests cover at least 2 controllers

**Dependency:** Depends on User Story #1 (testing suite)

---

#### User Story #7: Environment Configuration Documentation

**Priority: Medium | Story Points: 2**

**As a** new developer
**I want** clear setup documentation
**So that** I can run the project locally without confusion

**Acceptance Criteria:**

- README.md has prerequisites section
- Environment variables documented with examples
- Step-by-step setup instructions
- Common troubleshooting tips

**Personal Note:**
I've wasted hours on projects with bad docs. Making sure mine is good.

---

#### User Story #8: Database Integration Tests

**Priority: Medium | Story Points: 5**

**As a** developer
**I want** tests that verify database operations
**So that** I know my data layer is working correctly

**Acceptance Criteria:**

- Tests for creating tours in database
- Tests for querying tours
- Tests for updating and deleting
- Database cleans up after tests

**Technical Spike Needed:**
Research MongoDB memory server vs test containers vs mocking. Currently leaning toward mongodb-memory-server.

---

### 3. Definition of Done (My Personal Version)

A user story is "Done" when **I** am confident it meets these criteria:

#### The "Does It Actually Work?" Check

- [ ] I've tested it manually at least 3 times with different inputs
- [ ] It works on my machine (obviously) but I've also tested edge cases
- [ ] No crashes or unhandled errors

#### The "Future Me" Check

- [ ] Code is commented where it's not obvious
- [ ] Variable/function names make sense (I won't curse myself later)
- [ ] I could explain this code to someone in 2 minutes

#### The "Professional" Check

- [ ] Tests pass (npm test runs clean)
- [ ] No console.logs left (unless it's the logging feature)
- [ ] Git commit message explains WHY, not just WHAT
- [ ] CI pipeline actually ran and passed on GitHub

#### The "Lab Requirements" Check

- [ ] All acceptance criteria from user story are met
- [ ] Documentation updated if needed
- [ ] No known bugs (or if there are, they're documented)

**Personal Note:** The "professional" check is hardest for me. I tend to commit with messages like "fixed stuff" or "update". Need to be better about this.

---

### 4. Technical Stack Decisions

```
Backend: Node.js + Express (familiar)
Database: MongoDB + Mongoose (familiar)
Testing: Jest + Supertest (learning)
CI/CD: GitHub Actions (new)
Logging: Winston (leaning toward this) but Morgan (I'm familiar)
Environment: Node v24+ (whatever my laptop has)
```

**Why These Choices:**

- Node/Express/MongoDB: I've used them before, so I can focus on DevOps practices
- GitHub Actions: Built into GitHub, no extra setup
- Jest: Most popular, good community support

---

### 5. Sprint 1 Planning

#### Sprint Goal

**"Establish DevOps foundation with working CI/CD pipeline and automated tests"**

#### Why This Goal?

Sprint 1 requirements specifically ask for CI/CD and testing. This sets up everything else.

#### Sprint 1 Backlog

| Story     | Description                | Points | Dependencies | My Confidence |
| --------- | -------------------------- | ------ | ------------ | ------------- |
| #2        | CI/CD Pipeline Setup       | 8      | None         | Medium        |
| #1        | Automated Testing Suite    | 5      | None         | Low           |
| #3        | Health Monitoring Endpoint | 3      | None         | High          |
| **Total** |                            | **16** |              |               |

#### Sprint 1 Task Breakdown

**Story #2: CI/CD Pipeline Setup (8 points)**

- [ ] Task 2.1: Create `.github/workflows` directory
- [ ] Task 2.2: Create `ci.yml` workflow file (copy template from docs)
- [ ] Task 2.3: Add Node.js setup step
- [ ] Task 2.4: Add dependency installation step
- [ ] Task 2.5: Add linting step (ESLint)
- [ ] Task 2.6: Add test step (even if tests don't exist yet)
- [ ] Task 2.7: Test with dummy commit
- [ ] Task 2.8: Debug any failures (there will be some)
- [ ] Task 2.9: Add status badge to README.md

**Story #1: Automated Testing Suite (5 points)**

- [ ] Task 1.1: Install Jest and Supertest
- [ ] Task 1.2: Configure Jest (package.json or jest.config.js)
- [ ] Task 1.3: Write first test (simple math function to verify setup)
- [ ] Task 1.4: Write test for tour model validation
- [ ] Task 1.5: Write test for GET /api/v1/tours endpoint
- [ ] Task 1.6: Run tests locally and debug
- [ ] Task 1.7: Verify tests run in CI

**Story #3: Health Monitoring Endpoint (3 points)**

- [ ] Task 3.1: Create routes/health.js
- [ ] Task 3.2: Implement GET /health endpoint
- [ ] Task 3.3: Add timestamp and status
- [ ] Task 3.4: Add basic system info (Node version, uptime)
- [ ] Task 3.5: Test manually with curl/Postman
- [ ] Task 3.6: Write a simple test for health endpoint

#### Sprint 1 Risks & Mitigation

| Risk                                    | Likelihood | Impact | Mitigation                                         |
| --------------------------------------- | ---------- | ------ | -------------------------------------------------- |
| Tests failing in CI but passing locally | High       | High   | Research CI environment differences early          |
| GitHub Actions syntax errors            | High       | Medium | Start with minimal workflow, add steps gradually   |
| Running out of time                     | Medium     | High   | Focus on core stories, defer non-critical tasks    |
| MongoDB connection issues in CI         | Medium     | High   | Research in-memory MongoDB options before Sprint 1 |

#### My Sprint 1 Commitments

- I will commit code at least once per coding session (no end-of-sprint dump)
- I will write meaningful commit messages
- I will update this document as I learn
- If I get stuck for >1 hour, I'll document the problem and try something else

---

### 6. Sprint 1 Review Preparation

**Success Looks Like:**

- Green checkmark on GitHub Actions for main branch
- At least 3 passing tests
- Health endpoint returns 200 with timestamp
- I can explain what each part does

**Failure Looks Like:**

- Pipeline not working
- No tests written
- Last-minute rush commit

---

## Sprint 1: COMPLETED âœ…

**End Date:** February 17, 2026  
**Status:** All 3 stories completed (16 points)

### Sprint 1 Outcomes

âœ… Health Monitoring Endpoint - Working  
âœ… Automated Testing Suite - 18 tests passing  
âœ… CI/CD Pipeline - GitHub Actions configured

### Critical Issue Found & Fixed

**Issue:** CI/CD pipeline failed on first run with error:

```
Error: Dependencies lock file is not found in /home/runner/work/Natours/Natours
```

**Root Cause:** `package-lock.json` was in `.gitignore`, so GitHub Actions couldn't run `npm ci` (which requires the lock file).

**Fix:** Removed `package-lock.json` from `.gitignore` and pushed it to repository.

**Result:** âœ… All CI jobs passing (Test and Build on Node 24.x & 25.x, Code Quality Checks)

**Lesson Learned:** This validates Retrospective Improvement #1: "Verify CI/CD pipeline actually works on GitHub before declaring story done." I marked Story #2 as complete before checking GitHub Actions. Now I know to always verify.

---

### 8. Daily Log - Sprint 1

```
Sprint 1 - February 17, 2026:
- Created health endpoint (/api/v1/health) âœ…
- Configured Jest with 18 passing tests âœ…
- Set up GitHub Actions CI/CD pipeline âœ…
- Fixed browserslist configuration conflict
- Fixed ES module compatibility issue (file-type package)
- Created Sprint 1 Review and Retrospective
- ISSUE: CI failed - package-lock.json not in repo
- FIX: Removed package-lock.json from .gitignore
- RESULT: All CI checks passing âœ…
```

---

## Sprint 2: Planning & Execution

**Start Date:** February 17, 2026  
**Sprint Goal:** "Improve code quality with logging, additional tests, and complete documentation"

### Applying Sprint 1 Learnings

**From Retrospective - 3 Improvements:**

1. âœ… **Verify CI/CD on GitHub** - ALREADY LEARNED! Found package-lock.json issue
2. â° **30-minute debugging timer** - Will apply during Sprint 2
3. ðŸ“ **Continuous documentation** - Update docs as I work, not at end

---

### 9. Sprint 2 Backlog Selection

```
### 9. Sprint 2 Backlog Selection

**Selected Stories for Sprint 2:**

| Story                               | Points | Priority | Reason for Selection                           |
| ----------------------------------- | ------ | -------- | ---------------------------------------------- |
| #4: Error Logging & Monitoring      | 5      | High     | Demonstrates monitoring capability for rubric  |
| #7: Environment Config Docs         | 2      | Medium   | Quick win, improves project documentation      |
| #6: Input Validation Tests          | 5      | Medium   | Adds more test coverage, shows testing skills  |
| **TOTAL**                           | **12** |          | Reduced from 16 to focus on quality & learning |

**Why 12 points instead of 16?**

Sprint 1 taught me that testing takes 2x longer than estimated. Reducing story points to:
- Focus on applying the 3 improvements from retrospective
- Ensure higher quality delivery
- Leave time for documentation updates
- Avoid rushing at the end

---

### Sprint 2 Task Breakdown

**Story #4: Error Logging & Monitoring (5 points)**

- [ ] Task 4.1: Install Winston logging library
- [ ] Task 4.2: Create logger configuration file
- [ ] Task 4.3: Set up different log levels (error, warn, info)
- [ ] Task 4.4: Add file transports for production logging
- [ ] Task 4.5: Replace console.log with structured logging
- [ ] Task 4.6: Add request logging middleware
- [ ] Task 4.7: Test logging in different environments
- [ ] Task 4.8: Commit logging implementation

**Story #7: Environment Configuration Documentation (2 points)**

- [ ] Task 7.1: Document all required environment variables
- [ ] Task 7.2: Create .env.example file
- [ ] Task 7.3: Add setup instructions to README.md
- [ ] Task 7.4: Document Node.js version requirements
- [ ] Task 7.5: Add troubleshooting section
- [ ] Task 7.6: Commit documentation updates

**Story #6: Input Validation Tests (5 points)**

- [ ] Task 6.1: Write tests for tour model validation
- [ ] Task 6.2: Write tests for required field validation
- [ ] Task 6.3: Write tests for data type validation
- [ ] Task 6.4: Write tests for API error responses
- [ ] Task 6.5: Run tests and ensure all pass
- [ ] Task 6.6: Update test coverage report
- [ ] Task 6.7: Commit validation tests

---

### Sprint 2 Success Criteria

**Must Have:**
- Winston logging implemented with file output
- README.md has complete setup instructions
- At least 10 new validation tests passing
- All 3 retrospective improvements applied
- CI/CD pipeline still passing

**Nice to Have:**
- Test coverage >15%
- Log rotation configured
- API documentation in README

---

### Daily Log - Sprint 2 (To Be Updated)

```

Sprint 2 Day 1 - February 17, 2026:

- Created .env.example with all 18 environment variables documented
- Expanded README.md from 10 lines to 425 lines (comprehensive setup guide)
- Installed Winston logging library
- Created logger.js and requestLogger.js utilities
- Replaced all console.log/error with structured Winston logging
- Wrote 26 new validation tests for Tour model
- All 44 tests passing (18 from Sprint 1 + 26 from Sprint 2)
- 4 incremental commits pushed to GitHub
- CI/CD pipeline passing on all checks
- Sprint 2 Review and Retrospective completed

---

## Sprint 2: COMPLETED

**End Date:** February 17, 2026
**Status:** All 3 stories completed (12 points)

### Sprint 2 Outcomes

- Error Logging & Monitoring - Winston implemented with file rotation
- Environment Configuration Documentation - .env.example and comprehensive README
- Input Validation Tests - 26 tests covering Tour model validation

### Sprint 2 Improvements Applied

1. Verified CI/CD on GitHub before declaring done - Applied successfully
2. 30-minute debugging timer - Not needed (no major debugging issues)
3. Continuous documentation - Applied successfully (docs written as work progressed)

**Key Metrics:**

- Tests: 18 -> 44 (144% increase)
- Documentation: 10 lines -> 425 lines
- Debugging time: 2-3h (Sprint 1) -> 0h (Sprint 2)
- CI/CD verification: Done before completion

---

## Sprint 3: Planning & Execution

**Start Date:** February 17, 2026
**Sprint Goal:** "Complete comprehensive testing coverage and finalize API documentation"

### Applying Sprint 2 Learnings

From Sprint 2 Retrospective:

1. Continue verifying CI/CD on GitHub before declaring done
2. Keep documenting continuously (proven effective)
3. Use templates for repetitive work (speeds up development)
4. Maintain 12-point velocity (sustainable and quality-focused)

---

### Sprint 3 Backlog Selection

**Selected Stories for Sprint 3:**

| Story                           | Points | Priority | Reason for Selection                      |
| ------------------------------- | ------ | -------- | ----------------------------------------- |
| #8: Database Integration Tests  | 5      | Medium   | Comprehensive testing demonstration       |
| #5: Tour API Documentation      | 3      | Low      | Complete professional documentation       |
| Additional: Code Quality Review | 4      | High     | Ensure code meets professional standards  |
| **TOTAL**                       | **12** |          | Maintaining proven velocity from Sprint 2 |

**Why These Stories?**

1. Story #8 (Database Integration Tests) - Demonstrates comprehensive testing beyond unit tests
2. Story #5 (Tour API Documentation) - Completes the documentation suite
3. Code Quality Review - NEW story to ensure everything is production-ready

---

### Sprint 3 Task Breakdown

**Story #8: Database Integration Tests (5 points)**

- [ ] Task 8.1: Install mongodb-memory-server for testing
- [ ] Task 8.2: Configure test database setup and teardown
- [ ] Task 8.3: Write tests for creating tours in database
- [ ] Task 8.4: Write tests for querying tours from database
- [ ] Task 8.5: Write tests for updating tour documents
- [ ] Task 8.6: Write tests for deleting tours
- [ ] Task 8.7: Ensure database cleanup after each test
- [ ] Task 8.8: Verify all integration tests pass
- [ ] Task 8.9: Commit integration tests

**Story #5: Tour API Documentation (3 points)**

- [ ] Task 5.1: Document all tour API endpoints in README
- [ ] Task 5.2: Add request/response examples for each endpoint
- [ ] Task 5.3: Document authentication requirements
- [ ] Task 5.4: Add curl command examples
- [ ] Task 5.5: Document error response formats
- [ ] Task 5.6: Commit API documentation

**Story: Code Quality Review (4 points)**

- [ ] Task: Review all controller files for consistent error handling
- [ ] Task: Ensure all routes have proper validation
- [ ] Task: Check for any remaining console.log statements
- [ ] Task: Verify environment variables are properly used
- [ ] Task: Run linting and fix any issues
- [ ] Task: Update package.json scripts if needed
- [ ] Task: Final CI/CD verification
- [ ] Task: Commit quality improvements

---

### Sprint 3 Success Criteria

**Must Have:**

- Integration tests for database operations (at least 10 tests)
- Complete API documentation in README
- Code quality review completed
- All tests passing (target: 60+ total tests)
- CI/CD pipeline green
- No console.log statements remaining
- All environment variables documented

**Nice to Have:**

- Test coverage report
- Performance benchmarks
- API request examples in multiple formats

---

### Daily Log - Sprint 3

```
Sprint 3 Day 1 - February 17, 2026:
- Planned Sprint 3 with story selection (API Documentation, Integration Tests, Code Quality)
- Expanded README with comprehensive API documentation (850+ lines)
- Documented all tour, user, auth, review, and booking endpoints
- Added curl command examples and error response formats
- Installed mongodb-memory-server for in-memory database testing
- Created 26 integration tests for Tour model CRUD operations
- Solved User model dependency issue with mock schema
- All 70 tests passing (44 from Sprint 2 + 26 new integration tests)
- 2 incremental commits pushed to GitHub
- CI/CD pipeline passing on all checks
- Sprint 3 Review and Retrospective completed
```

---

## Sprint 3: COMPLETE

**End Date:** February 17, 2026
**Status:** All 3 stories completed (12 points)

### Sprint 3 Outcomes

- Tour API Documentation - Comprehensive docs with 30+ endpoints
- Database Integration Tests - 26 tests for full CRUD coverage
- Code Quality Review - 70 tests passing, CI/CD green

### Sprint 3 Key Achievements

- Test count: 44 -> 70 (59% increase)
- Documentation: 425 -> 850+ lines
- Integration testing skill acquired
- Template-driven documentation approach proven effective
- Consistent 12-point velocity maintained

**Key Metrics:**

- Tests: 70 total (18 health/error/async + 26 validation + 26 integration)
- Test Suites: 5 (health, appError, catchAsync, tourModel, tourDatabase)
- API Endpoints Documented: 30+
- Debugging time: 1h (User model dependency issue - resolved)

---

## Project Summary: 3 Sprints Complete

### Sprint Progression

**Sprint 0:** Planning and backlog creation  
**Sprint 1:** DevOps foundation (Health endpoint, 18 tests, CI/CD pipeline)  
**Sprint 2:** Quality improvements (Winston logging, comprehensive README, 26 validation tests)  
**Sprint 3:** Integration & documentation (Database tests, API docs, 26 integration tests)

### Final Metrics

| Metric                 | Total |
| ---------------------- | ----- |
| Sprints Completed      | 3     |
| Story Points Delivered | 40    |
| User Stories Completed | 7+    |
| Tests Written          | 70    |
| Test Suites            | 5     |
| Lines of Documentation | 1000+ |
| CI/CD Runs             | 15+   |
| Commits                | 14+   |

### Process Improvement Journey

**Sprint 1 Learnings:**

- Verify CI/CD on GitHub before declaring done
- Set 30-minute debugging timer
- Document continuously

**Sprint 2 Learnings:**

- Reduce velocity for quality (16 -> 12 points)
- Templates speed up repetitive work
- Continuous documentation is easier

**Sprint 3 Learnings:**

- Check model dependencies before integration tests
- Integration tests build real confidence
- Template ROI is massive

**Applied:** All learnings from previous sprints applied in subsequent sprints

---

### 10. Questions for My Instructor/Tutor

1. For monitoring/logging in Sprint 2, is simple file logging enough or should I look into external services?
2. How much test coverage is considered "good enough" for this lab?
3. Should I prioritize more tests or better documentation if I'm short on time?

---

## Self-Assessment Against Rubric (Final - After Sprint 3)

| Dimension           | Target                                             | Final Status                                               |
| ------------------- | -------------------------------------------------- | ---------------------------------------------------------- |
| Agile Practice      | Clear backlog, prioritization, acceptance criteria | Demonstrated through 3 sprints with continuous improvement |
| DevOps Practice     | CI/CD, tests, monitoring/logging                   | Fully implemented - CI/CD, 70 tests, Winston logging       |
| Delivery Discipline | No big-bang commits                                | 14+ incremental commits with meaningful messages           |
| Prototype Quality   | Working solution meets criteria                    | 70 tests passing, comprehensive docs, logging              |
| Reflection          | Meaningful improvement between sprints             | Applied all improvements from each retrospective           |

**Final Assessment:**

1. **Agile Practice: EXCELLENT**
   - 3 complete sprints with planning, execution, review, retrospective
   - Applied retrospective improvements in subsequent sprints
   - Adapted velocity based on learning (16 -> 12 points)

2. **DevOps Practice: EXCELLENT**
   - CI/CD pipeline with GitHub Actions
   - 70 passing tests (unit + integration)
   - Winston logging with file rotation
   - Environment configuration documented

3. **Delivery Discipline: EXCELLENT**
   - 14+ incremental commits
   - Meaningful commit messages
   - No big-bang commits
   - Verified CI/CD before declaring done

4. **Prototype Quality: EXCELLENT**
   - All 70 tests passing
   - Comprehensive documentation (1000+ lines)
   - Professional-grade code
   - CI/CD green

5. **Reflection: EXCELLENT**
   - Documented learnings in each retrospective
   - Applied improvements in subsequent sprints
   - Measurable progress: confidence 6 -> 8 -> 9

**Overall Project Grade: A**
